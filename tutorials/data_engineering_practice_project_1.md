# Description
An international firm that is looking to expand its business in different countries across the world has recruited you. You have been hired as a junior Data Engineer and are tasked with creating a script that can extract the list of the top 10 largest economies of the world in descending order of their GDPs in Billion USD (rounded to 2 decimal places), as logged by the International Monetary Fund (IMF).

The required data seems to be available on the URL mentioned below:


## what do we do 
Use Webscraping to extract required information from a website.
Use Pandas to load and process the tabular data as a dataframe.
Use Numpy to manipulate the information contatined in the dataframe.
Load the updated dataframe to CSV file.

```
# importing pandas and numpy
import numpy as np
import pandas as pd

# You can also use this section to suppress warnings generated by your code:
def warn(*args, **kwargs):
    pass
import warnings
warnings.warn = warn
warnings.filterwarnings('ignore')

# Extract the required GDP data from the given URL using Web Scraping.
URL="https://web.archive.org/web/20230902185326/https://en.wikipedia.org/wiki/List_of_countries_by_GDP_%28nominal%29" 
```

## Exercise 1: web scraping a page and reads tables, and get the table to process
```
import pandas as pd

URL="https://web.archive.org/web/20230902185326/https://en.wikipedia.org/wiki/List_of_countries_by_GDP_%28nominal%29"

# web scraping with read_html()
# Extract tables from webpage using Pandas. Retain table number 3 as the required dataframe.
# is this considered web sraping? Yes, this is a form of web scraping
#   (1) it parse the html file using a library called lxml or beautifulsoup. pandas will create a beautifulsoup object to parse the html structure
#   it uses .findall() function to get all html items with <table> tag within the html content
#   (2) each table found is converted into a pandas dataframe
#   (3) returns a list of dataframes
tables = pd.read_html(URL)
df = tables[3]

# Debugging and Learning
# print("number of tables in the page: ", len(tables))
# print(type(tables[0]))
# print(tables) # debugging purpose
# print(df.shape) the .shape in pandas is different from that in numpy. this returns rows and columns. in numpy returns number of dimension of an array

# Replace the column headers with column numbers
df.columns = range(df.shape[1]) # shape returns a tuple(number of rows, number of columns)

# Retain columns with index 0 and 2 (name of country and value of GDP quoted by IMF)
df = df[[0, 2]]
# print(df_gdp_by_country) # for debugging purpose

# Retain the Rows with index 1 to 10, indicating the top 10 economies of the world.
df = df.iloc[1:11, :]
print(df_gdp_by_country_top_10)

# Assign column names as "Country" and "GDP (Million USD)"
df.columns = ['Country', 'GDP (Million USD)']

# df # in jupyter notebook

# Exercise 2 - rounding and processing
# Change the data type of the 'GDP (Million USD)' column to integer. Use astype() method.
df['GDP (Million USD)'] = df['GDP (Million USD)'].astype(int)

# Convert the GDP value in Million USD to Billion USD
df[['GDP (Million USD)']] = df[['GDP (Million USD)']]/1000

# Use numpy.round() method to round the value to 2 decimal places.
df[['GDP (Million USD)']] = np.round(df[['GDP (Million USD)']], 2)

# Rename the column header from 'GDP (Million USD)' to 'GDP (Billion USD)'
df.rename(columns = {'GDP (Million USD)' : 'GDP (Billion USD)'})

# exercise 3 - converting to CSV
# Load the DataFrame to the CSV file named "Largest_economies.csv"
df.to_csv("./Largest_economies.csv")
```